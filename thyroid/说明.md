# 运行结果示例

```python
============================================================
无监督疾病判断任务
============================================================
============================================================
1. 数据加载与探索性分析
============================================================

训练集形状: (1839, 6)
测试集形状: (1933, 7)

特征维度: 6
训练集样本数: 1839 (全部为正常样本)
测试集样本数: 1933
测试集中患病样本数: 94 (4.86%)
测试集中正常样本数: 1839 (95.14%)

============================================================
2. 数据特征分析
============================================================

训练集特征统计:
         feature_1    feature_2    feature_3    feature_4    feature_5    feature_6
count  1839.000000  1839.000000  1839.000000  1839.000000  1839.000000  1839.000000
mean      0.008773    -0.116416     0.112331     0.059109    -0.033089     0.077651
std       0.992010     0.173841     1.008726     0.979351     0.975916     0.999772
min      -2.665449    -0.204296    -2.653929    -2.502275    -4.314267    -2.662200
25%      -0.818481    -0.191423    -0.295359    -0.544795    -0.552845    -0.452497
50%       0.131388    -0.152805     0.055057    -0.066300    -0.015499    -0.004584
75%       0.817404    -0.122769     0.378518     0.426695     0.253174     0.383607
max       2.136666     3.142602    11.551399     9.329607     5.250492    14.985562

训练集缺失值: 0
测试集缺失值: 0

特征分布图已保存为: result/feature_distributions.png
特征相关性矩阵已保存为: result/correlation_matrix.png

============================================================
3. 数据预处理
============================================================

数据已进行标准化处理
标准化后训练集均值: [-3.09099613e-17  2.31824710e-17 -1.44890444e-17 -1.73868532e-17
  5.79561775e-18  4.82968146e-18]
标准化后训练集标准差: [1. 1. 1. 1. 1. 1.]

============================================================
4. 模型训练
============================================================

Isolation Forest 训练中, contamination=0.024, n_estimators=1000

模型训练完成!

============================================================
5. 模型评估
============================================================

孤立森林评估指标:
  Accuracy Precision  Recall F1-Score AUC-ROC Avg Precision
0   0.9659    0.5972  0.9149   0.7227  0.9794        0.7810

------------------------------------------------------------
混淆矩阵
------------------------------------------------------------
真阴性(TN): 1781, 假阳性(FP): 58
假阴性(FN): 8, 真阳性(TP): 86
特异度(Specificity): 0.9685
灵敏度(Sensitivity/Recall): 0.9149

混淆矩阵图已保存为: result/confusion_matrix.png
ROC曲线图已保存为: result/roc_curve.png
PR曲线图已保存为: result/pr_curve.png
PCA可视化图已保存为: result/pca_visualization.png

============================================================
任务完成!
============================================================

生成的文件:
- feature_distributions.png: 特征分布图
- correlation_matrix.png: 特征相关性矩阵
- confusion_matrix.png: 混淆矩阵
- roc_curve.png: ROC曲线 (如可计算)
- pr_curve.png: Precision-Recall曲线 (如可计算)
- pca_visualization.png: PCA降维可视化
```



## 1. 选择合适的无监督方法，并阐述理由

### 选择的方法：**Isolation Forest（孤立森林）**

### 理由阐述：

#### **(1) 问题特点分析**
- **训练集只有正常样本**：这是典型的**异常检测**问题，而非传统的分类问题
- **测试集包含正常和患病样本**：需要识别出偏离正常模式的异常（疾病）样本
- **医疗场景的不平衡性**：疾病样本通常是少数类

#### **(2) Isolation Forest 的优势**

```python
# 核心原理
self.model = IsolationForest(
    contamination=0.024,      # 预期异常比例（疾病率）
    n_estimators=1000,        # 使用1000棵树提高稳定性
    max_samples='auto',       # 自动选择样本量
    random_state=42,
    n_jobs=-1                 # 并行计算
)
```

其中`contamination`和`n_estimators`为可调参数

**为什么适合这个任务：**

| 特点                  | 说明                                 | 在本任务中的体现               |
| --------------------- | ------------------------------------ | ------------------------------ |
| **无需标签训练**      | 只用正常样本训练，学习"正常"模式     | 训练集全为正常样本             |
| **高效处理高维数据**  | 时间复杂度 O(n log n)，适合多特征    | 有多个生理指标特征             |
| **对异常敏感**        | 通过"隔离"异常点，异常点更容易被分离 | 疾病样本的生理指标偏离正常范围 |
| **contamination参数** | 可根据先验知识设置异常比例           | 设为0.024匹配测试集疾病率      |
| **输出异常分数**      | 提供连续分数用于ROC/PR分析           | 便于医疗场景的风险评估         |

#### **(3) 与其他方法的对比**

```python
# 其他可能的方法：
# K-Means:  假设数据有明确聚类结构，不适合异常检测
# GMM: 需要假设数据分布，医疗数据分布复杂
# One-Class SVM: 对高维数据计算成本高，参数敏感
# Autoencoder: 需要更多数据和调参，可解释性差
#
# Isolation Forest: 无分布假设，高效，可解释
```

---

## 2. 实现模型并训练

### 完整的实现流程：

#### **(1) 数据加载与探索**

```python
def load_data(self, train_path: str, test_path:  str) -> list[str]:
    """
    关键步骤：
    1. 读取CSV文件
    2. 提取feature开头的列作为特征
    3. 分离特征(X)和标签(y)
    """
    train_df = pd.read_csv(train_path)
    test_df = pd.read_csv(test_path)
    
    # 动态识别特征列
    feature_cols = [col for col in train_df. columns if col.startswith('feature')]
    
    # 注意：训练集无标签（或全为0），测试集有标签
    self.X_train = train_df[feature_cols].to_numpy()
    self.X_test = test_df[feature_cols].to_numpy()
    self.y_test = test_df['label'].to_numpy()  # 仅用于评估
```

**输出示例：**

```
训练集形状:  (3600, 6)  # 有6个特征
测试集形状: (3428, 7)  # 有label列
特征维度: 6
训练集样本数: 3600 (全部为正常样本)
测试集样本数: 3428
测试集中患病样本数: 82 (2.39%)
```

#### **(2) 特征工程与可视化**

```python
def explore_data(self, feature_cols: list[str]) -> None:
    """
    关键分析：
    1. 特征分布对比（正常 vs 患病）
    2. 特征相关性矩阵
    """
    # 多类别直方图叠加
    axes[idx].hist(self.X_train[:, idx], ...)        # 训练集正常
    axes[idx].hist(self.X_test[self.y_test==0, idx], ...)  # 测试集正常
    axes[idx].hist(self. X_test[self.y_test==1, idx], ...)  # 测试集患病
    
    # 特征相关性分析
    correlation_matrix = np.corrcoef(self.X_train.T)
    sns.heatmap(correlation_matrix, ...)
```

**生成图表：**

- `feature_distributions.png`：识别哪些特征对区分疾病最有帮助
- `correlation_matrix.png`：检查特征冗余性

#### **(3) 数据预处理**

```python
def preprocess_data(self) -> None:
    """
    标准化处理：
    - 均值=0, 标准差=1
    - 消除不同特征的量纲影响
    """
    self.scaler = StandardScaler()
    self.X_train_scaled = self.scaler.fit_transform(self.X_train)
    self.X_test_scaled = self.scaler.transform(self.X_test)  # 使用训练集参数
```

**为什么标准化重要：**
```python
# 示例：特征量级差异
feature1:  [0.5, 0.8, 1.2]      # 甲状腺激素水平 (μg/dL)
feature2: [80, 120, 150]       # 心率 (bpm)

# 不标准化 → feature2会主导距离计算
# 标准化后 → 所有特征贡献平等
```

#### **(4) 模型训练**

```python
def train_model(self, contamination: float = 0.05, n_estimators: int = 200) -> None:
    """
    关键参数：
    - contamination:  预期异常比例（需根据数据调整）
    - n_estimators: 树的数量（更多=更稳定，但计算慢）
    """
    self.model = IsolationForest(
        contamination=contamination,
        n_estimators=n_estimators,
        max_samples='auto',      # 每棵树用256个样本
        random_state=42,         # 可复现
        n_jobs=-1                # 使用所有CPU核心
    )
    self.model.fit(self.X_train_scaled)  # 只用正常样本训练
```

**训练过程：**
1. 随机选择特征和分割点
2. 构建1000棵隔离树
3. 记录每个样本的平均路径长度（异常分数）

---

## 3. 评估判断效果

### **(1) 核心评估指标**

```python
def evaluate_model(self) -> None:
    # 预测标签（-1=异常，1=正常）
    raw_pred = self.model.predict(self.X_test_scaled)
    y_pred = (raw_pred == -1).astype(int)  # 转为0/1格式
    
    # 异常分数（用于ROC/PR曲线）
    scores = -self.model.score_samples(self.X_test_scaled)
```

#### **分类指标**

| 指标            | 计算公式              | 医疗意义                             |
| --------------- | --------------------- | ------------------------------------ |
| **Accuracy**    | (TP+TN)/(TP+TN+FP+FN) | 总体准确率（不平衡数据下参考意义小） |
| **Precision**   | TP/(TP+FP)            | 预测为患病的准确性（减少误诊）       |
| **Recall**      | TP/(TP+FN)            | 找出实际患病的比例（避免漏诊）       |
| **F1-Score**    | 2×(P×R)/(P+R)         | 精确率和召回率的调和平均             |
| **Specificity** | TN/(TN+FP)            | 正确识别健康人的能力                 |

#### **混淆矩阵解读**

```python
# 示例输出：
#              预测正常  预测患病
# 实际正常      1781       58      ← FP=58  (假阳性/误诊)
# 实际患病         8       86      ← FN=8   (假阴性/漏诊)

tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()

# 医疗决策权衡：
# - 降低FN（漏诊）更重要 → 调高contamination参数
# - 降低FP（误诊）避免过度治疗 → 调低contamination参数
```

**生成图表：**`confusion_matrix.png`

### **(2) 曲线分析**

#### **ROC曲线（AUC-ROC）**

```python
fpr, tpr, thresholds = roc_curve(y_test, scores)
auc = roc_auc_score(y_test, scores)

# AUC解释：
# 0.5 = 随机猜测
# 0.7-0.8 = 可接受
# 0.8-0.9 = 良好
# >0.9 = 优秀
```

**优势**：评估模型在所有阈值下的性能

**生成图表：**`roc_curve.png`

#### **PR曲线（Precision-Recall）**

```python
precision, recall, thresholds = precision_recall_curve(y_test, scores)
avg_precision = average_precision_score(y_test, scores)

# 不平衡数据下比ROC更有参考价值
# AP（Average Precision）接近1表示性能好
```

**生成图表：**`pr_curve.png`

### **(3) 可视化分析**

#### **PCA降维可视化**

```python
pca = PCA(n_components=2)
X_test_pca = pca.fit_transform(X_test_scaled)

# 左图：真实标签分布
# 右图：模型预测分布
# 对比两图 → 直观看出预测错误的区域
```

**解读要点：**

- 聚类明显 → 疾病样本确实偏离正常模式
- 边界模糊 → 可能存在亚临床状态，需要更多特征

**生成图表：**`pca_visualization.png`

---

## 总结与优化建议

### 当前实现的优点：
- 完整的数据探索流程  

- 合理的特征工程  
- 多维度的评估体系  
- 清晰的可视化展示  

### 可能的改进方向：

```python
# 1. 超参数优化
from sklearn.model_selection import GridSearchCV
param_grid = {
    'contamination': [0.01, 0.024, 0.05],
    'n_estimators': [500, 1000, 1500]
}

# 2. 特征选择
from sklearn.feature_selection import SelectKBest
selector = SelectKBest(k=5)  # 选择最重要的5个特征

# 3. 集成方法
from sklearn.ensemble import VotingClassifier
# 结合多种异常检测算法

# 4. 阈值调整
optimal_threshold = find_threshold_by_metric(scores, y_test, metric='f1')
```

### 评估效果判断标准：

| 场景         | 重点指标            | 期望值              |
| ------------ | ------------------- | ------------------- |
| **疾病筛查** | Recall（召回率）    | >0.85（尽量少漏诊） |
| **确诊检验** | Precision（精确率） | >0.90（避免误诊）   |
| **综合评估** | F1-Score, AUC       | F1>0.75, AUC>0.85   |

代码设置（contamination=0.024），模型倾向于**保守预测**，适合初筛场景，可根据实际需求调整参数权衡。