## 1. 选择合适的无监督方法，并阐述理由

### 选择的方法：**Isolation Forest（孤立森林）**

### 理由阐述：

#### **(1) 问题特点分析**
- **训练集只有正常样本**：这是典型的**异常检测**问题，而非传统的分类问题
- **测试集包含正常和患病样本**：需要识别出偏离正常模式的异常（疾病）样本
- **医疗场景的不平衡性**：疾病样本通常是少数类

#### **(2) Isolation Forest 的优势**

```python
# 核心原理
self.model = IsolationForest(
    contamination=0.024,      # 预期异常比例（疾病率）
    n_estimators=1000,        # 使用1000棵树提高稳定性
    max_samples='auto',       # 自动选择样本量
    random_state=42,
    n_jobs=-1                 # 并行计算
)
```

**为什么适合这个任务：**

| 特点                  | 说明                                 | 在本任务中的体现               |
| --------------------- | ------------------------------------ | ------------------------------ |
| **无需标签训练**      | 只用正常样本训练，学习"正常"模式     | 训练集全为正常样本             |
| **高效处理高维数据**  | 时间复杂度 O(n log n)，适合多特征    | 有多个生理指标特征             |
| **对异常敏感**        | 通过"隔离"异常点，异常点更容易被分离 | 疾病样本的生理指标偏离正常范围 |
| **contamination参数** | 可根据先验知识设置异常比例           | 设为0.024匹配测试集疾病率      |
| **输出异常分数**      | 提供连续分数用于ROC/PR分析           | 便于医疗场景的风险评估         |

#### **(3) 与其他方法的对比**

```python
# 其他可能的方法：
# K-Means:  假设数据有明确聚类结构，不适合异常检测
# GMM: 需要假设数据分布，医疗数据分布复杂
# One-Class SVM: 对高维数据计算成本高，参数敏感
# Autoencoder: 需要更多数据和调参，可解释性差
#
# Isolation Forest: 无分布假设，高效，可解释
```

---

## 2. 实现模型并训练

### 完整的实现流程：

#### **(1) 数据加载与探索**

```python
def load_data(self, train_path: str, test_path:  str) -> list[str]:
    """
    关键步骤：
    1. 读取CSV文件
    2. 提取feature开头的列作为特征
    3. 分离特征(X)和标签(y)
    """
    train_df = pd.read_csv(train_path)
    test_df = pd.read_csv(test_path)
    
    # 动态识别特征列
    feature_cols = [col for col in train_df. columns if col.startswith('feature')]
    
    # 注意：训练集无标签（或全为0），测试集有标签
    self.X_train = train_df[feature_cols].to_numpy()
    self.X_test = test_df[feature_cols].to_numpy()
    self.y_test = test_df['label'].to_numpy()  # 仅用于评估
```

**输出示例：**
```
训练集形状:  (3600, 6)  # 有6个特征
测试集形状: (3428, 7)  # 有label列
特征维度: 6
训练集样本数: 3600 (全部为正常样本)
测试集样本数: 3428
测试集中患病样本数: 82 (2.39%)
```

#### **(2) 特征工程与可视化**

```python
def explore_data(self, feature_cols: list[str]) -> None:
    """
    关键分析：
    1. 特征分布对比（正常 vs 患病）
    2. 特征相关性矩阵
    """
    # 多类别直方图叠加
    axes[idx].hist(self.X_train[:, idx], ...)        # 训练集正常
    axes[idx].hist(self.X_test[self.y_test==0, idx], ...)  # 测试集正常
    axes[idx].hist(self. X_test[self.y_test==1, idx], ...)  # 测试集患病
    
    # 特征相关性分析
    correlation_matrix = np.corrcoef(self.X_train.T)
    sns.heatmap(correlation_matrix, ...)
```

**生成图表：**
- `feature_distributions.png`：识别哪些特征对区分疾病最有帮助
- `correlation_matrix.png`：检查特征冗余性

#### **(3) 数据预处理**

```python
def preprocess_data(self) -> None:
    """
    标准化处理：
    - 均值=0, 标准差=1
    - 消除不同特征的量纲影响
    """
    self.scaler = StandardScaler()
    self.X_train_scaled = self.scaler.fit_transform(self.X_train)
    self.X_test_scaled = self.scaler.transform(self.X_test)  # 使用训练集参数
```

**为什么标准化重要：**
```python
# 示例：特征量级差异
feature1:  [0.5, 0.8, 1.2]      # 甲状腺激素水平 (μg/dL)
feature2: [80, 120, 150]       # 心率 (bpm)

# 不标准化 → feature2会主导距离计算
# 标准化后 → 所有特征贡献平等
```

#### **(4) 模型训练**

```python
def train_model(self, contamination: float = 0.05, n_estimators: int = 200) -> None:
    """
    关键参数：
    - contamination:  预期异常比例（需根据数据调整）
    - n_estimators: 树的数量（更多=更稳定，但计算慢）
    """
    self.model = IsolationForest(
        contamination=contamination,
        n_estimators=n_estimators,
        max_samples='auto',      # 每棵树用256个样本
        random_state=42,         # 可复现
        n_jobs=-1                # 使用所有CPU核心
    )
    self.model.fit(self.X_train_scaled)  # 只用正常样本训练
```

**训练过程：**
1. 随机选择特征和分割点
2. 构建1000棵隔离树
3. 记录每个样本的平均路径长度（异常分数）

---

## 3. 评估判断效果

### **(1) 核心评估指标**

```python
def evaluate_model(self) -> None:
    # 预测标签（-1=异常，1=正常）
    raw_pred = self.model.predict(self.X_test_scaled)
    y_pred = (raw_pred == -1).astype(int)  # 转为0/1格式
    
    # 异常分数（用于ROC/PR曲线）
    scores = -self.model.score_samples(self.X_test_scaled)
```

#### **分类指标**

| 指标            | 计算公式              | 医疗意义                             |
| --------------- | --------------------- | ------------------------------------ |
| **Accuracy**    | (TP+TN)/(TP+TN+FP+FN) | 总体准确率（不平衡数据下参考意义小） |
| **Precision**   | TP/(TP+FP)            | 预测为患病的准确性（减少误诊）       |
| **Recall**      | TP/(TP+FN)            | 找出实际患病的比例（避免漏诊）       |
| **F1-Score**    | 2×(P×R)/(P+R)         | 精确率和召回率的调和平均             |
| **Specificity** | TN/(TN+FP)            | 正确识别健康人的能力                 |

#### **混淆矩阵解读**

```python
# 示例输出：
#              预测正常  预测患病
# 实际正常      3200      146      ← FP=146 (假阳性/误诊)
# 实际患病        18       64      ← FN=18  (假阴性/漏诊)

tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()

# 医疗决策权衡：
# - 降低FN（漏诊）更重要 → 调高contamination参数
# - 降低FP（误诊）避免过度治疗 → 调低contamination参数
```

### **(2) 曲线分析**

#### **ROC曲线（AUC-ROC）**

```python
fpr, tpr, thresholds = roc_curve(y_test, scores)
auc = roc_auc_score(y_test, scores)

# AUC解释：
# 0.5 = 随机猜测
# 0.7-0.8 = 可接受
# 0.8-0.9 = 良好
# >0.9 = 优秀
```

**优势**：评估模型在所有阈值下的性能

#### **PR曲线（Precision-Recall）**

```python
precision, recall, thresholds = precision_recall_curve(y_test, scores)
avg_precision = average_precision_score(y_test, scores)

# 不平衡数据下比ROC更有参考价值
# AP（Average Precision）接近1表示性能好
```

### **(3) 可视化分析**

#### **PCA降维可视化**

```python
pca = PCA(n_components=2)
X_test_pca = pca.fit_transform(X_test_scaled)

# 左图：真实标签分布
# 右图：模型预测分布
# 对比两图 → 直观看出预测错误的区域
```

**解读要点：**
- 聚类明显 → 疾病样本确实偏离正常模式
- 边界模糊 → 可能存在亚临床状态，需要更多特征

---

## 总结与优化建议

### 当前实现的优点：
- 完整的数据探索流程  

- 合理的特征工程  
- 多维度的评估体系  
- 清晰的可视化展示  

### 可能的改进方向：

```python
# 1. 超参数优化
from sklearn.model_selection import GridSearchCV
param_grid = {
    'contamination': [0.01, 0.024, 0.05],
    'n_estimators': [500, 1000, 1500]
}

# 2. 特征选择
from sklearn.feature_selection import SelectKBest
selector = SelectKBest(k=5)  # 选择最重要的5个特征

# 3. 集成方法
from sklearn.ensemble import VotingClassifier
# 结合多种异常检测算法

# 4. 阈值调整
optimal_threshold = find_threshold_by_metric(scores, y_test, metric='f1')
```

### 评估效果判断标准：

| 场景         | 重点指标            | 期望值              |
| ------------ | ------------------- | ------------------- |
| **疾病筛查** | Recall（召回率）    | >0.85（尽量少漏诊） |
| **确诊检验** | Precision（精确率） | >0.90（避免误诊）   |
| **综合评估** | F1-Score, AUC       | F1>0.75, AUC>0.85   |

根据代码设置（contamination=0.024），模型倾向于**保守预测**，适合初筛场景，可根据实际需求调整参数权衡。