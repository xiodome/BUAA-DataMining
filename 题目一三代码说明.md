# 题目一

### 运行成功，结果如下：

#### **指标**：

KMeans 与 Ward 均为 ARI=1.0000，NMI=1.0000，Silhouette=0.4326，Davies-Bouldin=1.0839（完全匹配真值）。

PCA 主成分数 282，累计解释方差 0.95。

输出已生成：G:\大学\大三上\数据挖掘\聚类任务\Cluster\outputs

metrics_summary.json

kmeans_tsne.png、agglomerative_tsne.png

预测 CSV（kmeans/agglomerative）

#### **报告可写要点**：

特征：RGB+HSV 直方图，LBP+HOG；预处理 resize、灰度强度归一化。

算法：KMeans（含 StandardScaler+PCA 保留95%方差）和 Ward 层次聚类。

评估：Silhouette、DBI、ARI、NMI；本次在有标签下达到 ARI/NMI=1。

可视化：两张 t-SNE（KMeans、Ward）位于 outputs 目录。

如需提交作业，可直接使用上述指标和可视化；若要进一步稳健性展示，可附上无标签时的 Silhouette/DBI，或尝试不同随机种子/主成分阈值对比。

### 疑问解答

#### **指标**

- adjusted_rand_index (ARI)：1.0000（越接近1越好，1表示与真值完全一致）
- normalized_mutual_info (NMI)：1.0000（同上，越接近1越好）
- silhouette：0.4326（轮廓系数，[-1,1]，越大越好，>0 表示簇分得还行）
- davies_bouldin：1.0839（DBI，越小越好，接近0最好）
- 当前结果：KMeans 和 Ward 两种算法的 ARI/NMI 都是 1，说明聚类结果与提供的标签完全一致；Silhouette ≈0.43，DBI ≈1.08 也处在合理区间。查看方式：
- 终端输出：运行时在 “=== 指标汇总 ===” 部分已经打印。
- 文件：G:\大学\大三上\数据挖掘\聚类任务\Cluster\outputs\metrics_summary.json，用任意文本/IDE查看即可。
- 可视化：kmeans_tsne.png 和 agglomerative_tsne.png 在同一 outputs 目录。

#### **代码解读**

1) ##### 依赖和数据结构

用到的库：Pillow/NumPy/Scikit-Image（图像处理与特征）、Scikit-Learn（PCA、KMeans、层次聚类、评估、t-SNE）、Matplotlib（画图）。

ImageRecord：一个小数据类，存一张图片的路径和可选标签。

2) ##### 数据读取

list_image_files：列出数据集目录下所有图片文件。

load_labels：读 JSON 标签（文件名 -> 类别名）。

prepare_records：把路径和标签打包成 ImageRecord 列表。

3) ##### 特征提取（每张图片）

预处理：读取为 RGB，resize 到 256×256，转灰度并归一化。

颜色特征：extract_color_histograms 计算 RGB 和 HSV 直方图并拼接。

纹理特征：extract_texture_features 计算 LBP 直方图 + HOG 特征。

extract_features 返回拼好的特征向量；build_feature_matrix 把所有图片的特征叠成矩阵，并记录文件名。

4) ##### 标签编码（可选）

encode_labels：如果提供了真值标签，就把类别名映射成整数数组；否则返回 None，用于只跑无监督指标。

5) ##### 聚类算法

run_kmeans：先标准化，再 PCA 保留 95% 方差，然后 KMeans（n_init=20, max_iter=500）；返回聚类标签、PCA 信息、降维后数据。

run_agglomerative：对降维后的特征做 Ward 层次聚类。

6) ##### 评估指标

evaluate_clustering：无论有没有真值，都算 Silhouette、Davies-Bouldin；有真值时再算 ARI、NMI。

7) ##### 可视化

run_tsne：对特征做 t-SNE 降到 2D（兼容新版 sklearn 的参数）。

plot_clusters：按聚类标签画散点图并保存 PNG。

8) ##### 输出与汇总

print_metrics_table：把各算法指标打印成表格。

dump_predictions：输出 CSV（文件名, 预测簇）。

##### 主流程 main：

读取数据和标签，提特征

跑 KMeans 和层次聚类

评估并打印表格

做 t-SNE 可视化并保存

可选写 metrics_summary.json

命令行参数：--dataset 数据目录，--labels 标签 JSON（可选），--output-dir 输出目录，--n-clusters（默认6），--random-state，--save-metrics（保存 JSON）。

运行后你会在 outputs/ 看到：

metrics_summary.json：两种算法的各项指标

kmeans_tsne.png、agglomerative_tsne.png：可视化

kmeans_predictions.csv、agglomerative_predictions.csv：预测结果 CSV

 

#### **总流程**

##### 命令示例

python cluster_solution.py --dataset Cluster/dataset --labels Cluster/cluster_labels.json --output-dir Cluster/outputs --save-metrics

##### 主要流程

- 特征：RGB+HSV 直方图 + LBP + HOG；图像先 resize(256×256)、灰度归一化。
- 降维/聚类：StandardScaler → PCA(保留95%方差) → KMeans（n_init=20, max_iter=500）；同一嵌入上再做 Ward 层次聚类。
- 评估：Silhouette、Davies-Bouldin；若有真值，计算 ARI、NMI、clustering_accuracy（匈牙利算法）。
- 可视化：t-SNE 2D 散点（KMeans/Ward 各一张）。
- 本次运行结果（有标签）
- ARI = 1.0000，NMI = 1.0000，clustering_accuracy = 1.0000
- Silhouette = 0.4326，Davies-Bouldin = 1.0839
- PCA 主成分数 = 282，累计解释方差 = 0.95
- 生成文件（Cluster/outputs）
- metrics_summary.json
- kmeans_tsne.png、agglomerative_tsne.png
- kmeans_predictions.csv、agglomerative_predictions.csv

##### 依赖

pip install pillow scikit-image scikit-learn matplotlib numpy（Matplotlib 中文可能缺字，警告不影响结果）

 

# 题目三

### **目录与主要文件**

weather.csv：原始数据，每 10 分钟一行，含时间戳和 21 个气象指标（含目标 OT）。时间列默认 date，目标列默认 ot。运行脚本必须提供这个文件路径。

weather_forecasting.py：主程序，包含

参数解析：--data-path、--history（历史步长）、--forecast-horizon（预测步长）、--train-ratio、--model 等。

数据预处理：列名清洗为 ASCII，可读；按时间排序；插值补缺 + 前向/后向填充；滑动窗口构造 (history=12, horizon=1)；按时间顺序切分训练/测试；StandardScaler 仅用训练集拟合。

模型选择与训练：train_model 支持 gbrt_default、gbrt_light、random_forest、hist_gbrt、ridge。调用 evaluate_metrics 计算 MAE / RMSE / R2 / MAPE。

导出：预测结果 CSV、指标 JSON、可选保存窗口数据 npz。

forecasts.csv（或类似 forecasts_*.csv）：测试集逐行预测结果。列含

timestamp：该预测对应的真实时间点

y_true：真实室外温度

y_pred：模型预测值

error：y_pred - y_true（正表示高估，负表示低估）

metrics.json、metrics_*.json：训练集与测试集的指标汇总，例如

MAE：平均绝对误差

RMSE：均方根误差

R2：判定系数（1 越好，0 相当于均值基线，<0 表示差于均值）

MAPE(%)：百分比绝对误差

其它输出（若使用不同模型）：

forecasts_hist.csv / metrics_hist.json：HistGradientBoosting 最优结果

forecasts_gbrt_light.csv / metrics_gbrt_light.json：浅树 GBRT

forecasts_rf.csv / metrics_rf.json：随机森林

forecasts_ridge.csv / metrics_ridge.json：线性基线

 

### 结果

生成的**结果**说明（基于 history=12，train_ratio=0.8 的多模型实验）：

指标汇总（测试集表现，数值在对应的 metrics_.json）

hist_gbrt（当前最优）：MAE≈11.19，RMSE≈22.33，R2≈0.02，MAPE≈2.59%

gbrt_default：MAE≈56.76，RMSE≈205.28，R2≈-81.51，MAPE≈13.58%

gbrt_light：MAE≈32.36，RMSE≈173.41，R2≈-57.87，MAPE≈7.63%

random_forest：MAE≈40.37，RMSE≈155.46，R2≈-46.32，MAPE≈9.53%

ridge：MAE≈40.88，RMSE≈61.76，R2≈-6.47，MAPE≈9.70%

#### 指标文件

metrics_hist.json：最优模型 HistGradientBoosting 的训练/测试 MAE、RMSE、R2、MAPE

其他模型对应：metrics.json（原始 gbrt_default）、metrics_gbrt_light.json、metrics_rf.json、metrics_ridge.json

预测结果文件（逐行时间点）

格式：timestamp, y_true, y_pred, error（error = 预测 - 真实）

forecasts_hist.csv：最优模型的逐点预测与误差

其他模型对应：forecasts.csv（gbrt_default）、forecasts_gbrt_light.csv、forecasts_rf.csv、forecasts_ridge.csv

#### **如何阅读**

快速看整体：打开对应的 metrics_*.json，测试集指标是主要关心的泛化表现。

看局部误差：在 forecasts_*.csv 中按 |error| 排序，可定位误差最大的时间段；也可以筛选正误差（高估）和负误差（低估）分别查看。

最优选择：当前 hist_gbrt 显著优于其余模型，建议在报告中重点展示其指标；可将其他模型作为对照说明改进效果。

#### **复现实验命令**（最优模型示例）

 python weather_forecasting.py --data-path weather.csv --history 12 --forecast-horizon 1 --train-ratio 0.8 --model hist_gbrt --pred-output forecasts_hist.csv --metrics-output metrics_hist.json

 

#### **代码结构与内容说明**（weather_forecasting.py）

1) ##### 顶层依赖与数据结构

依赖：pandas、numpy、scikit-learn（GradientBoosting/RandomForest/HistGBRT/Ridge、StandardScaler、metrics）、argparse、Path 等。

数据类：

DatasetInfo: dataframe、feature_columns、target_column、time_column

WindowedSamples: X (samples, history, n_features)，y，timestamps

2) ##### 参数解析 build_parser

关键参数：

--data-path 必填，CSV 路径

--history（默认 12），--forecast-horizon（默认 1）

--train-ratio（默认 0.8，时间顺序切分）

--time-column（默认 date），--target-column（默认 ot）

--model 选择模型：gbrt_default / gbrt_light / random_forest / hist_gbrt / ridge

输出：--pred-output、--metrics-output、--save-window-data

3) ##### 数据预处理

列名清洗 sanitize_column: 将特殊字符替换为 ASCII，转小写，用下划线分隔。

读取与清洗 load_dataset:

读 CSV → 重命名列 → 校验时间/目标列

时间列转 datetime，按时间排序

数值列全转数值（不可转为 NaN）

以时间为索引插值（method="time"），再 ffill/bfill

构造特征列列表（除目标列）

滑动窗口 build_windows:

输入：history, forecast_horizon

输出：X [n, history, n_feat]，y [n]，预测对应的 timestamps

时间顺序切分 chronological_split:

按比例取前段为训练，后段为测试，确保不打乱时间

标准化 standardize:

将 3D 窗口展平为 2D，使用训练集拟合 StandardScaler，再分别 transform 训练/测试，避免数据泄漏

4) ##### 模型训练与评估

train_model(model_name, X_train, y_train):

gbrt_default: GradientBoostingRegressor(n_estimators=600, lr=0.05, max_depth=3, subsample=0.8)

gbrt_light: 更浅更少树 (n_estimators=250, max_depth=2, subsample=0.85)

random_forest: RF(n_estimators=400, max_depth=12, min_samples_leaf=3, n_jobs=-1)

hist_gbrt: HistGradientBoostingRegressor(max_iter=300, max_depth=8, lr=0.08)

ridge: Ridge(alpha=1.0)

全部 random_state=42（除 ridge）

评估 evaluate_metrics:

MAE、RMSE、R2、MAPE(%)（对 y=0 做裁剪防除零）

导出：

save_predictions: 保存 timestamp/y_true/y_pred/error

save_metrics: 保存指标 JSON

save_window_npz: 可选保存窗口化样本

5) ##### 主流程 main

解析参数 → 加载/清洗数据 → 构建窗口 →（可选）保存窗口 npz

按时间切分训练/测试 → 标准化

训练模型（根据 --model）→ 训练/测试预测

打印训练/测试指标 → 可选保存预测 CSV 和指标 JSON

6) ##### 运行示例

python weather_forecasting.py \

 --data-path weather.csv \

 --history 12 \

 --forecast-horizon 1 \

 --train-ratio 0.8 \

 --model hist_gbrt \

 --pred-output outputs_ts/forecasts_hist.csv \

 --metrics-output outputs_ts/metrics_hist.json

7) ##### 结果文件含义

forecasts_*.csv**：逐时间点预测（timestamp, y_true, y_pred, error**）*

metrics_*.json**：训练/**测试的 MAE**、RMSE**、R2**、MAPE*

outputs_ts/：整理后的输出目录（已移动所有预测/指标文件）

8) ##### 初学者阅读建议

先看主流程 main 把控顺序

再看数据预处理（sanitize/load/build_windows/chronological_split/standardize）

然后看 train_model 了解可选模型与超参

最后看 evaluate_metrics 和导出函数，理解输出格式

**当前最佳模型**

hist_gbrt 在测试集表现最好（MAE≈11.19，MAPE≈2.59%，R2≈0.02），建议作为报告主结果；其余模型可作为对照展示改进幅度。

#### **结果数据分析**（基于 history=12，train_ratio=0.8 多模型对比）

##### 总体结论

性能最好的是 hist_gbrt：测试集 MAE≈11.19，RMSE≈22.33，MAPE≈2.59%，R2≈0.02，显著优于原始 GBRT，且 R2 转正（略高于均值基线）。

其他模型均存在明显欠佳的泛化：gbrt_default 和 gbrt_light、random_forest、ridge 的 R2 皆为负，误差远高于 hist_gbrt，说明过拟合或模型不适配特征形态。

##### 分模型要点（测试集）

gbrt_default：MAE 56.76，RMSE 205.28，R2 -81.51，MAPE 13.58%。过拟合明显（训练 R2≈0.96）。

gbrt_light：MAE 32.36，RMSE 173.41，R2 -57.87，MAPE 7.63%。浅树减轻过拟合但仍不足。

random_forest：MAE 40.37，RMSE 155.46，R2 -46.32，MAPE 9.53%。稳定但精度不够。

ridge：MAE 40.88，RMSE 61.76，R2 -6.47，MAPE 9.70%。线性基线，拟合能力弱。

hist_gbrt：MAE 11.19，RMSE 22.33，R2 0.02，MAPE 2.59%。目前最优。

##### 误差解读与排查建议

逐点误差：在 outputs_ts/forecasts_hist.csv 中按 |error| 排序，定位最大偏差的时间段，检查是否对应异常天气或传感器尖峰。

偏差方向：error = y_pred - y_true；正值表示高估，负值表示低估。可筛选正、负误差分布，观察系统性偏差。

稳健性：R2 稍高于 0，说明相对均值基线略有提升但仍可优化（可尝试更细调参或加统计特征）。

##### 文件定位

指标 JSON：outputs_ts/metrics_hist.json（最优），其余模型指标在 metrics*.json。

预测 CSV：outputs_ts/forecasts_hist.csv（最优），其余模型预测在 forecasts*.csv。

脚本：weather_forecasting.py（可通过 --model hist_gbrt 复现）。