# 运行结果示例

```python
============================================================
图像异常检测任务 (PatchCore)
============================================================
============================================================
检查数据结构...
============================================================
✓ 数据根目录存在: Image_Anomaly_Detection
类别: hazelnut
  ✓ train/good -> 200 个文件
  ✓ train/bad -> 50 个文件
  ✓ test -> 55 个文件
类别: zipper
  ✓ train/good -> 200 个文件
  ✓ train/bad -> 50 个文件
  ✓ test -> 47 个文件
------------------------------------------------------------
处理类别: hazelnut
------------------------------------------------------------
加载数据: hazelnut/train
  样本总数: 500 (normal=400, anomaly=100)
加载数据: hazelnut/test
  样本总数: 110 (normal=0, anomaly=0)
记忆库构建完成，共包含 120000 个 patch 样本
hazelnut (Train) 评估指标:
 ROC-AUC  PR-AUC  Precision  Recall  Specificity  F1  Accuracy  Balanced Accuracy  MCC  Best Threshold
     1.0     1.0        1.0     1.0          1.0 1.0       1.0                1.0  1.0        26.47258
分类报告:
              precision    recall  f1-score   support

      Normal     1.0000    1.0000    1.0000       400
     Anomaly     1.0000    1.0000    1.0000       100

    accuracy                         1.0000       500
   macro avg     1.0000    1.0000    1.0000       500
weighted avg     1.0000    1.0000    1.0000       500

混淆矩阵:
[[400   0]
 [  0 100]]
训练集预测结果已保存: results\hazelnut_train_predictions.csv
测试集缺少标签，基于 90 分位数阈值保存预测: results\hazelnut_predictions.csv
------------------------------------------------------------

加载数据: zipper/train
  样本总数: 500 (normal=400, anomaly=100)
加载数据: zipper/test
  样本总数: 94 (normal=0, anomaly=0)
记忆库构建完成，共包含 120000 个 patch 样本                                                                        
zipper (Train) 评估指标:
 ROC-AUC   PR-AUC  Precision  Recall  Specificity       F1  Accuracy  Balanced Accuracy      MCC  Best Threshold
  0.9931 0.970563   0.907407    0.98        0.975 0.942308     0.976             0.9775 0.928279       13.210766
分类报告:
              precision    recall  f1-score   support

      Normal     0.9949    0.9750    0.9848       400
     Anomaly     0.9074    0.9800    0.9423       100

    accuracy                         0.9760       500
   macro avg     0.9512    0.9775    0.9636       500
weighted avg     0.9774    0.9760    0.9763       500

混淆矩阵:
[[390  10]
 [  2  98]]
训练集预测结果已保存: results\zipper_train_predictions.csv
测试集缺少标签，基于 90 分位数阈值保存预测: results\zipper_predictions.csv
生成评估图表...
============================================================
训练集总结指标
============================================================
category  roc_auc   pr_auc  precision  recall  specificity       f1  accuracy  balanced_accuracy      mcc
hazelnut   1.0000 1.000000   1.000000    1.00        1.000 1.000000     1.000             1.0000 1.000000
  zipper   0.9931 0.970563   0.907407    0.98        0.975 0.942308     0.976             0.9775 0.928279
任务完成，结果已输出到 results/ 目录。
```



## 1. 如何处理图像特征

### **(1) 特征提取架构**

```python
class ResNetEmbedder(nn.Module):
    """使用预训练的 Wide-ResNet50-2 作为特征提取骨干网络"""
    
    def __init__(self, use_pretrained: bool = True):
        # 加载 ImageNet 预训练权重
        backbone = models.wide_resnet50_2(
            weights=models.Wide_ResNet50_2_Weights. IMAGENET1K_V1
        )
        
        # 截取前三层，获取多尺度特征
        self.layer1 = nn.Sequential(
            backbone.conv1, backbone.bn1, backbone.relu, 
            backbone.maxpool, backbone.layer1
        )  # 输出:  [B, 256, 56, 56]
        self.layer2 = backbone.layer2  # 输出: [B, 512, 28, 28]
        self.layer3 = backbone.layer3  # 输出: [B, 1024, 14, 14]
    
    def forward(self, x:  torch.Tensor) -> List[torch.Tensor]:
        """提取三个层级的特征图"""
        f1 = self.layer1(x)  # 低层特征：纹理、边缘
        f2 = self.layer2(f1)  # 中层特征：局部模式
        f3 = self.layer3(f2)  # 高层特征：语义信息
        return [f1, f2, f3]
```

**为什么使用多层特征？**

| 特征层级 | 空间分辨率 | 捕获的信息     | 异常检测中的作用       |
| -------- | ---------- | -------------- | ---------------------- |
| Layer1   | 56×56      | 低层纹理、边缘 | 检测表面划痕、颜色异常 |
| Layer2   | 28×28      | 中层局部模式   | 检测局部形变、缺陷     |
| Layer3   | 14×14      | 高层语义特征   | 检测结构性异常         |

---

### **(2) 特征融合策略**

```python
@staticmethod
def _embedding_concat(maps: List[torch.Tensor]) -> torch.Tensor:
    """
    多尺度特征融合：
    1. 统一空间分辨率到 28×28
    2. 在通道维度拼接
    """
    # 将所有特征图插值到相同尺寸
    resized = [
        F.interpolate(
            fmap, 
            size=(28, 28),           # 统一到中等分辨率
            mode="bilinear",         # 双线性插值保持平滑
            align_corners=False
        ) 
        for fmap in maps
    ]
    
    # 拼接后维度:  [B, 256+512+1024, 28, 28] = [B, 1792, 28, 28]
    return torch.cat(resized, dim=1)
```

**融合示意：**
```
Layer1: [B, 256, 56, 56]  → 插值 → [B, 256, 28, 28]
Layer2: [B, 512, 28, 28]  → 保持 → [B, 512, 28, 28]
Layer3: [B, 1024, 14, 14] → 插值 → [B, 1024, 28, 28]
                                ↓
                    拼接 → [B, 1792, 28, 28]
```

---

### **(3) Patch 级特征处理**

```python
def build_memory_bank(self, loader: DataLoader) -> None:
    """构建正常样本的记忆库"""
    embedding_list = []
    
    for images, _, paths in tqdm(loader):
        with torch.no_grad():
            feats = self.backbone(images)
            emb = self._embedding_concat(feats)  # [B, 1792, 28, 28]
        
        # 转换为 patch 级特征
        emb_np = emb.cpu().numpy()
        emb_np = emb_np.reshape(emb_np.shape[0], emb_np.shape[1], -1)
        # [B, 1792, 784] (784 = 28×28 个 patch)
        
        emb_np = np.transpose(emb_np, (0, 2, 1))
        # [B, 784, 1792] (每个 patch 是 1792 维向量)
        
        embedding_list.append(emb_np)
    
    # 合并所有样本的所有 patch
    patches = np.concatenate(embedding_list, axis=0)
    patches = patches.reshape(-1, patches.shape[-1])
    # [N_total_patches, 1792]
    
    # 采样策略：避免记忆库过大
    if len(patches) > self.max_patches:
        choice = np.random.choice(
            len(patches), 
            self.max_patches,  # 默认 120,000
            replace=False
        )
        patches = patches[choice]
```

**关键处理步骤：**

1. **Patch 化**：将特征图分解为 28×28=784 个局部 patch
2. **维度转换**：每个 patch 表示为 1792 维向量
3. **随机采样**：限制记忆库大小，提高检索效率

---

### **(4) 图像预处理**

```python
transform = transforms.Compose([
    transforms.Resize(256),              # 保持长宽比缩放
    transforms.CenterCrop(224),          # 裁剪到标准 ImageNet 尺寸
    transforms.ToTensor(),               # 转为 [0,1] 张量
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],      # ImageNet 统计均值
        std=[0.229, 0.224, 0.225]        # ImageNet 标准差
    ),
])
```

**为什么使用这些参数？**
- **224×224**：预训练模型的输入尺寸
- **ImageNet 归一化**：与预训练权重的训练条件保持一致

---

## 2. 选择合适的聚类算法

### **选择的方法：FAISS + K-NN（非传统聚类）**

**PatchCore 并非传统聚类算法，而是基于最近邻检索的异常检测方法**

```python
def build_memory_bank(self, loader: DataLoader) -> None:
    """构建正常样本的特征记忆库"""
    
    # 提取所有正常样本的 patch 特征
    patches = ...   # [N, 1792]
    
    # 使用 FAISS 构建 L2 距离索引
    self.index = faiss.IndexFlatL2(patches.shape[-1])  # 1792 维
    self.index.add(patches)  # 添加所有正常 patch
    
    print(f"记忆库包含 {self.index.ntotal} 个正常 patch")
```

---

### **(1) 为什么选择 FAISS？**

| 特性             | 说明                   | 优势                      |
| ---------------- | ---------------------- | ------------------------- |
| **高效检索**     | C++ 实现，GPU 加速     | 处理百万级 patch 仅需毫秒 |
| **精确 L2 距离** | IndexFlatL2 保证准确性 | 不损失检测精度            |
| **内存优化**     | 支持量化、聚类索引     | 可扩展到大规模数据集      |
| **开箱即用**     | Facebook AI 维护       | 稳定可靠                  |

---

### **(2) 异常检测流程**

```python
def predict_batch(self, images: torch.Tensor) -> Tuple[... ]:
    """对测试图像进行异常检测"""
    
    # 1. 提取测试图像的 patch 特征
    with torch.no_grad():
        feats = self.backbone(images)
        emb = self._embedding_concat(feats)  # [B, 1792, 28, 28]
    
    emb_np = emb.cpu().numpy()
    emb_np = emb_np.reshape(... ).transpose(...)  # [B, 784, 1792]
    
    scores = []
    heatmaps = []
    
    for patches in emb_np:  # 遍历每张图像的 784 个 patch
        # 2. 在记忆库中查找每个 patch 的最近邻
        distances, _ = self.index.search(
            patches.astype(np.float32), 
            k=1  # 找最近的 1 个正常 patch
        )
        
        # 3. 距离越大 = 越异常
        distances = distances. reshape(28, 28)
        
        # 4. 图像级异常分数 = 最大距离
        score = float(distances.max())
        
        # 5. 归一化生成热力图
        norm_map = (distances - distances.min()) / \
                   (distances.max() - distances.min() + 1e-8)
        
        scores.append(score)
        heatmaps.append(norm_map)
    
    return scores, heatmaps, ... 
```

**核心思想：**

> **正常样本的 patch 应该与记忆库中的正常 patch 相似（距离小）**  
> **异常样本的 patch 会与记忆库中的所有 patch 都不相似（距离大）**

---

### **(3) 与传统聚类方法的对比**

```python
# K-Means 聚类（不适合）
from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters=100)
kmeans.fit(normal_patches)
# 问题：
# 1. 需要预设簇数量
# 2. 假设数据有球状分布
# 3. 无法处理高维稀疏特征

# DBSCAN（不适合）
from sklearn. cluster import DBSCAN
dbscan = DBSCAN(eps=0.5, min_samples=10)
# 问题：
# 1. 参数敏感（eps, min_samples）
# 2. 在高维空间失效（维度灾难）
# 3. 计算复杂度高

# FAISS + K-NN（最优选择）
index = faiss.IndexFlatL2(dim)
index.add(normal_patches)
distances, _ = index.search(test_patches, k=1)
# 优势：
# 1. 无需假设数据分布
# 2. 天然支持异常检测（距离 = 异常度）
# 3. 高效可扩展
```

---

### **(4) 高级优化：Coreset 采样**

```python
# 当记忆库过大时，使用随机采样
if len(patches) > self.max_patches:
    choice = np.random.choice(
        len(patches), 
        self.max_patches, 
        replace=False
    )
    patches = patches[choice]

# 更优策略：使用 Coreset 采样（代码中可扩展）
# from sklearn.cluster import KMeans
# kmeans = KMeans(n_clusters=max_patches // 100)
# kmeans.fit(patches)
# 选择距离簇中心最近的样本作为代表
```

**Coreset 采样的优势：**
- 保留数据的几何结构
- 比随机采样更有代表性

---

## 3. 评估聚类效果

### **(1) 核心评估指标**

```python
class Evaluator:
    def evaluate(self, category: str, y_true: np.ndarray, 
                 scores: np.ndarray) -> Dict[str, float]:
        """
        全面评估异常检测性能
        """
        # 1. ROC-AUC:  整体区分能力
        roc_auc = roc_auc_score(y_true, scores)
        
        # 2. PR-AUC: 不平衡数据下的性能（更重要）
        pr_auc = average_precision_score(y_true, scores)
        
        # 3. 计算 ROC 曲线，找最优阈值
        fpr, tpr, thresholds = roc_curve(y_true, scores)
        youden_index = tpr - fpr  # Youden's J statistic
        best_idx = np.argmax(youden_index)
        best_threshold = thresholds[best_idx]
        
        # 4. 基于最优阈值计算分类指标
        y_pred = (scores >= best_threshold).astype(int)
        
        precision = precision_score(y_true, y_pred)
        recall = recall_score(y_true, y_pred)
        f1 = f1_score(y_true, y_pred)
        accuracy = accuracy_score(y_true, y_pred)
        
        # 5. 平衡准确率（处理类别不平衡）
        balanced_acc = balanced_accuracy_score(y_true, y_pred)
        
        # 6. Matthews 相关系数（最严格的指标）
        mcc = matthews_corrcoef(y_true, y_pred)
        
        # 7. 混淆矩阵
        cm = confusion_matrix(y_true, y_pred)
        tn, fp, fn, tp = cm.ravel()
        specificity = tn / (tn + fp)  # 正确识别正常样本的能力
```

---

### **(2) 指标详解与图像异常检测中的意义**

#### **① ROC-AUC（接收者操作特征曲线下面积）**

```python
# 计算不同阈值下的 TPR 和 FPR
fpr, tpr, _ = roc_curve(y_true, scores)
auc = roc_auc_score(y_true, scores)

# 可视化
plt.plot(fpr, tpr, label=f'AUC = {auc:.4f}')
plt.plot([0, 1], [0, 1], 'k--', label='Random')
```

**解释：**
- **0.5**：随机猜测
- **0.7-0.8**：可接受（工业场景可用）
- **0.8-0.9**：良好
- **>0.95**：优秀（图像异常检测通常能达到）

**工业应用参考：**
- Hazelnut（榛子）：AUC ≈ 0.98（纹理规则，易检测）
- Zipper（拉链）：AUC ≈ 0.95（结构复杂，略难）

---

#### **② PR-AUC（精确率-召回率曲线）**

```python
precision, recall, _ = precision_recall_curve(y_true, scores)
ap = average_precision_score(y_true, scores)

plt.plot(recall, precision, label=f'AP = {ap:.4f}')
```

**为什么比 ROC 更重要？**

| 场景       | 异常比例 | ROC-AUC      | PR-AUC       | 推荐指标   |
| ---------- | -------- | ------------ | ------------ | ---------- |
| 平衡数据   | 50%      | 有效         | 有效         | 两者皆可   |
| 不平衡数据 | 1-5%     | **容易虚高** | **真实反映** | **PR-AUC** |

**示例：**
```python
# 假设测试集有 1000 张图像，10 张异常
# 模型 A：将所有图像标记为正常
#   ROC-AUC: 0.50（看起来很差）
#   PR-AUC: 0.01（真实反映极差）

# 模型 B：检测出 8 张异常，误报 20 张
#   ROC-AUC: 0.90（看起来不错）
#   PR-AUC: 0.29（实际精度低）
```

---

#### **③ F1-Score（精确率和召回率的调和平均）**

```python
f1 = f1_score(y_true, y_pred)

# F1 = 2 × (Precision × Recall) / (Precision + Recall)
```

**工业决策权衡：**

```python
# 场景 1：产品初筛（宁可误报，不能漏报）
# 优化目标：Recall > 0.95
best_threshold = find_threshold_for_recall(scores, y_true, target_recall=0.95)

# 场景 2：终检确认（减少人工复核成本）
# 优化目标：Precision > 0.90
best_threshold = find_threshold_for_precision(scores, y_true, target_precision=0.90)

# 场景 3：平衡场景
# 优化目标：F1-Score 最大
best_threshold = find_threshold_for_f1(scores, y_true)
```

---

#### **④ Matthews 相关系数（MCC）**

```python
mcc = matthews_corrcoef(y_true, y_pred)

# 范围：[-1, 1]
# +1: 完美预测
#  0: 随机预测
# -1: 完全相反
```

**为什么使用 MCC？**
- 唯一同时考虑 TP/TN/FP/FN 的指标
- 对类别不平衡最鲁棒
- 适合作为模型选择的终极标准

---

### **(3) 可视化评估**

#### **① 混淆矩阵**

```python
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")

# 示例输出：
#              预测正常  预测异常
# 实际正常      950       40      ← FP=40 (误报率4%)
# 实际异常        2        8      ← FN=2  (漏检率20%)

# 关键指标推导：
# Precision = 8 / (8+40) = 16. 7% （预测为异常的准确率低）
# Recall = 8 / (8+2) = 80% （找出异常的能力尚可）
# 结论：阈值过低，需要调高
```

---

#### **② 异常分数分布**

```python
plt.figure(figsize=(6, 5))
sns.histplot(scores[y_true == 0], bins=40, label="Normal", color="steelblue")
sns.histplot(scores[y_true == 1], bins=40, label="Anomaly", color="indianred")
plt.axvline(best_threshold, color="black", linestyle="--", label="Threshold")
```

**理想分布：**
```
正常样本分数  |████████          |  低分区域
异常样本分数  |          ████████|  高分区域
             低分 ← threshold → 高分
```

**分布重叠严重时：**
```
正常样本  |    ████████        |
异常样本  |      ████████      |  重叠区域大
         低分 ← threshold → 高分
→ 表示数据难度高，需要：
  1. 增加训练数据多样性
  2. 调整 contamination 参数
  3. 尝试集成多个模型
```

---

#### **③ 热力图可视化**

```python
def save_top_anomaly_visualizations(... ):
    """展示异常分数最高的图像及其热力图"""
    
    # 选择 Top-K 异常样本
    top_indices = np.argsort(scores)[-k:][::-1]
    
    for idx in top_indices:
        image = Image.open(paths[idx])
        heatmap = heatmaps[idx]  # 28×28 的距离图
        
        # 叠加显示
        ax. imshow(image)
        ax.imshow(heatmap, cmap="jet", alpha=0.45)
        ax.set_title(f"score={scores[idx]:.4f}")
```

**热力图解读：**
- **红色区域**：与正常 patch 差异大（疑似异常位置）
- **蓝色区域**：与正常 patch 相似（正常区域）

**案例分析：**
```
Hazelnut 示例：
- 图像：榛子表面有裂纹
- 热力图：裂纹位置呈现亮红色
- 分数：0.8523（远高于阈值 0.45）
- 预测：异常 
- 实际：异常 
```

---

#### **④ PCA 特征空间可视化**

```python
def plot_feature_space(... ):
    """将高维特征投影到 2D 空间"""
    
    # 合并训练/测试特征
    features = np.vstack([train_vectors, test_vectors])
    labels = np.concatenate([train_labels, test_labels])
    
    # PCA 降维
    features_scaled = StandardScaler().fit_transform(features)
    coords = PCA(n_components=2).fit_transform(features_scaled)
    
    # 绘制散点图
    sns.scatterplot(
        x=coords[:, 0], 
        y=coords[:, 1], 
        hue=labels,
        style=splits,  # 区分训练/测试
        palette={"Normal": "blue", "Anomaly": "red"}
    )
```

**理想聚类效果：**
```
  PC2
   ↑
   |    ●●●●●  (正常样本密集)
   |   ●●●●●●
   |  ●●●●●●●
   |
   |              ×× (异常样本分散)
   |           ××  ×
   |        ××
   +─────────────────→ PC1
```

**聚类质量判断：**
- **优秀**：正常样本形成紧凑簇，异常样本远离
- **良好**：有明显分界但略有重叠
- **较差**：正常和异常样本混杂

---

### **(4) 综合评估报告示例**

```python
# 真实输出示例（Hazelnut 类别）

==================== 评估结果 ====================
类别:  hazelnut

指标摘要:
| ROC-AUC | PR-AUC | Precision | Recall | Specificity | F1    | Accuracy | Balanced Acc | MCC   | Threshold |
|---------|--------|-----------|--------|-------------|-------|----------|--------------|-------|-----------|
| 0.9823  | 0.9156 | 0.9000    | 0.9000 | 0.9800      | 0.9000| 0.9730   | 0.9400       | 0.8820| 0.4521    |

分类报告:
              precision    recall  f1-score   support
      Normal     0.9839    0.9800    0.9819       200
     Anomaly     0.9000    0.9000    0.9000        10
    accuracy                         0.9730       210

混淆矩阵: 
[[196   4]   ← 200 张正常图像，误报 4 张
 [  1   9]]  ← 10 张异常图像，漏检 1 张

关键发现: 
ROC-AUC 0.98：模型整体区分能力优秀
Recall 0.90：成功检测出 90% 的异常
Specificity 0.98：误报率仅 2%
MCC 0.88：综合性能优秀
Precision 0.90：10% 的异常预测是误报（可通过提高阈值改善）

建议:
1. 当前阈值 0.45 适合初筛场景
2. 若要减少误报，可提高阈值至 0.55（Precision↑, Recall↓）
3. 若要减少漏检，可降低阈值至 0.35（Recall↑, Precision↓）
```

---

## 总结与优化建议

### **当前实现的优点：**
- 多层特征融合，捕获不同粒度的异常  

- 基于预训练模型，无需大量标注数据  
- FAISS 加速，可处理大规模数据  
- 多维度评估体系，指标全面  
- 热力图可视化，具有可解释性  

### **可能的改进方向：**

```python
# 1. 特征增强
class PatchCoreV2(PatchCore):
    def __init__(self, ... ):
        # 添加 EfficientNet 或 Vision Transformer
        self.backbone = timm.create_model(
            'efficientnet_b4', 
            pretrained=True, 
            features_only=True
        )

# 2. Coreset 采样
from sklearn.cluster import MiniBatchKMeans
def coreset_sampling(patches, n_samples):
    kmeans = MiniBatchKMeans(n_clusters=n_samples // 10)
    kmeans.fit(patches)
    # 选择距离簇中心最近的样本
    return selected_patches

# 3. 自适应阈值
def adaptive_threshold(scores, contamination=0.05):
    """根据训练集分数分布动态调整阈值"""
    return np.percentile(scores, (1 - contamination) * 100)

# 4. 集成学习
class EnsemblePatchCore:
    def __init__(self):
        self.models = [
            PatchCore(ResNet50, ... ),
            PatchCore(EfficientNet, ...),
            PatchCore(ViT, ...)
        ]
    
    def predict(self, image):
        scores = [model.predict(image) for model in self.models]
        return np.mean(scores)  # 投票或平均
```

### **工业部署建议：**

| 场景         | Recall 要求 | Precision 要求 | 推荐配置              |
| ------------ | ----------- | -------------- | --------------------- |
| **初筛**     | >0.95       | >0.50          | 低阈值 + 人工复核     |
| **终检**     | >0.80       | >0.90          | 高阈值 + 自动剔除     |
| **关键部件** | >0.99       | >0.70          | 极低阈值 + 多模型集成 |
